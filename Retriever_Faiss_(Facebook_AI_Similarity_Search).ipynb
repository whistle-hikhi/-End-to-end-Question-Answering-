{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfmUCdimfUKAVIJXV/HfJD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "UMnS3_ton_kW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYBTEyx0n5D1"
      },
      "outputs": [],
      "source": [
        "!pip install-qq transformers[sentencepiece]==4.35.2 datasets==2.16.1 evaluate==0.4.1\n",
        "!sudo apt-get install libomp-dev\n",
        "!pip install-qq faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import collections\n",
        "import torch\n",
        "import faiss\n",
        "import evaluate\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "Xt_t15H5oEp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset: SQuAD2.0"
      ],
      "metadata": {
        "id": "uGrbEzhZoGpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_NAME = 'squad_v2'\n",
        "raw_datasets = load_dataset(DATASET_NAME, split='train+validation')\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "JMyfpwV4oJ1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove unsovled labels"
      ],
      "metadata": {
        "id": "0ylvBEyFoMif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = raw_datasets.filter(\n",
        "  lambda x: len(x['answers']['text']) > 0\n",
        ")"
      ],
      "metadata": {
        "id": "smnrFPAloQDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "VitQk32NoSdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModel.from_pretrained(MODEL_NAME).to(device)"
      ],
      "metadata": {
        "id": "Cj1hs2V_oTie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector embedding"
      ],
      "metadata": {
        "id": "4leLp4-noWPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_pooling(model_output):\n",
        "  return model_output.last_hidden_state[:, 0]"
      ],
      "metadata": {
        "id": "M6twsoOHoYBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text_list):\n",
        "\n",
        "    encoded_input = tokenizer(\n",
        "        text_list,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
        "    model_output = model(**encoded_input)\n",
        "    return cls_pooling(model_output)"
      ],
      "metadata": {
        "id": "k2Mxf9r6oZ2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector database"
      ],
      "metadata": {
        "id": "vL16iHVmob4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_COLUMN = 'question_embedding'\n",
        "embeddings_dataset = raw_datasets.map(\n",
        "    lambda x: {\n",
        "        EMBEDDING_COLUMN: get_embeddings(\n",
        "        x['question']\n",
        "        ).detach().cpu().numpy()[0]\n",
        "        }\n",
        ")"
      ],
      "metadata": {
        "id": "n-3Jps93odud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dataset.add_faiss_index(column=EMBEDDING_COLUMN)"
      ],
      "metadata": {
        "id": "sbJR5_2_ohDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_question = 'When did Beyonce start becoming popular?'\n",
        "\n",
        "input_quest_embedding = get_embeddings([input_question])\n",
        "input_quest_embedding = input_quest_embedding.cpu().detach().numpy()\n",
        "\n",
        "TOP_K = 5\n",
        "scores, samples = embeddings_dataset.get_nearest_examples(\n",
        "\n",
        "EMBEDDING_COLUMN, input_quest_embedding, k=TOP_K\n",
        ")\n",
        "\n",
        "for idx, score in enumerate(scores):\n",
        "\n",
        " print(f'Top {idx + 1}\\tScore: {score}')\n",
        " print(f'Question: {samples[\"question\"][idx]}')\n",
        " print(f'Context: {samples[\"context\"][idx]}')\n",
        " print()"
      ],
      "metadata": {
        "id": "LUloFcqpoh3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply model"
      ],
      "metadata": {
        "id": "QaG4oURzolDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "PIPELINE_NAME = 'question-answering'\n",
        "MODEL_NAME = 'thangduong0509/distilbert-finetuned-squadv2'\n",
        "pipe = pipeline(PIPELINE_NAME, model=MODEL_NAME)"
      ],
      "metadata": {
        "id": "JkEth0_eomGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Input question: {input_question}')\n",
        "for idx, score in enumerate(scores):\n",
        "\n",
        " question = samples[\"question\"][idx]\n",
        "\n",
        " context = samples[\"context\"][idx]\n",
        " answer = pipe(\n",
        " question=question,\n",
        " context=context\n",
        " )\n",
        " print(f'Top {idx + 1}\\tScore: {score}')\n",
        " print(f'Context: {context}')\n",
        " print(f'Answer: {answer}')\n",
        " print()"
      ],
      "metadata": {
        "id": "u5FLCUxPorV8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}